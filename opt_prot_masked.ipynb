{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "from Ampep.toxic_func import toxic_feature\n",
    "from Ampep.amp_func import amp_feature\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('prot_t5_xl_bfd')\n",
    "model = T5ForConditionalGeneration.from_pretrained('prot_t5_xl_bfd').to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "\n",
    "def similarity_score(seq1, seq2):\n",
    "    alignments = pairwise2.align.globalxx(seq1,seq2)\n",
    "    lens = max(len(seq1), len(seq2))\n",
    "    try:\n",
    "        return  -alignments[0].score/lens\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(alignments)\n",
    "        print(seq1)\n",
    "        print(seq2)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gradient(z, q, beta, criterion, sigma=100):\n",
    "    z_dim = z.shape[1:]\n",
    "    u = np.random.normal(0, sigma, size=(q, z_dim[0],z_dim[1])).astype('float32')\n",
    "    u = torch.from_numpy(u / np.linalg.norm(u, axis=1, keepdims=True)).to(device='cuda')\n",
    "\n",
    "    f_0 = criterion(z)\n",
    "    f_tmp = criterion(z + beta*u)\n",
    "    print('Loss now: %f'%(f_0[0]))\n",
    "    # print(f_0)\n",
    "    u = u.to(device='cpu')\n",
    "    # print(u.device)\n",
    "    return torch.mean(z_dim[1] * u * np.expand_dims(np.expand_dims(f_tmp - f_0, 1),1)/ beta, dim=0,\n",
    "                      keepdims=True).to(dtype = z.dtype, device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_encode(seq):\n",
    "    mask_rate = 0.15\n",
    "    len_seq = len(seq)\n",
    "    mask_len = int(len_seq * mask_rate)\n",
    "    mask_idx = random.sample(range(len_seq), mask_len)\n",
    "    \n",
    "    raw_input = list(seq)\n",
    "    for i,idx in enumerate(mask_idx):\n",
    "        raw_input[idx] = '<extra_id_%d>'%i\n",
    "    raw_input = [' '.join(raw_input)]\n",
    "    inputs = tokenizer(raw_input, return_tensors='pt')['input_ids'].to('cuda')\n",
    "    r1 = model.encoder.forward(inputs)['last_hidden_state']\n",
    "    return r1\n",
    "\n",
    "def model_decode(emb):\n",
    "    outputs = [0]\n",
    "    for i in range(0, 100):\n",
    "        out = model.decoder.forward(torch.tensor([outputs], device='cuda'), encoder_hidden_states= emb)\n",
    "        out = model.lm_head(out['last_hidden_state'])\n",
    "        out = torch.softmax(out, dim = -1)\n",
    "        out = torch.argmax(out, dim = -1)\n",
    "        outputs.append(int(out[0][i]))\n",
    "        if out[0][-1] == 1:\n",
    "            break\n",
    "        if outputs[-1] < 3 or outputs[-1] > 22:\n",
    "            outputs[-1] = 23\n",
    "        if i >= int(emb.shape[1] * 1.2):\n",
    "            break\n",
    "    seq = tokenizer.decode(outputs[1:-1])\n",
    "    seq = ''.join(seq.split())\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(z, model,origin_seq ,weight=1, score=None, constraints=[],\n",
    "                  weight_constraint=False):\n",
    "\n",
    "    res = []\n",
    "    num = z.shape[0]\n",
    "    for i in range(num):\n",
    "        seq = model_decode(torch.unsqueeze(z[i], dim=0))\n",
    "\n",
    "        loss_property = score(seq, origin_seq) if score else 0\n",
    "\n",
    "        loss_constraint = 0\n",
    "        for c in constraints:\n",
    "            loss_constraint += c(seq)\n",
    "\n",
    "        loss =  (loss_property + loss_constraint*weight if weight_constraint else\n",
    "            loss_property*weight + loss_constraint)\n",
    "        res.append(loss)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "def optimize(model, seq, q=100, base_lr=0.1, max_iter=1000, num_restarts=1,\n",
    "             weight=0.1, beta=1, use_adam=False, early_stop=False, score=similarity_score,\n",
    "             constraints=[amp_feature, toxic_feature], writer=None, run_str=None, results_dir='results',\n",
    "             init_best={}, write_log=None, flip_weight=False):\n",
    "    z_0 = model_encode(seq)     #获得序列的embedding\n",
    "    print(seq)\n",
    "    loss = partial(loss_function, model=model, origin_seq = seq,weight=weight, score=score,\n",
    "                   constraints=[amp_feature, toxic_feature], weight_constraint=flip_weight)\n",
    "    best = {'score': -np.inf, 'found': False, 'early_stop': False}\n",
    "    best.update(init_best)\n",
    "    \n",
    "    for k in range(num_restarts):\n",
    "        if best['early_stop']:\n",
    "            break\n",
    "        z = z_0.clone()\n",
    "        for i in (range(max_iter)):\n",
    "            print('start itr %d'%i)\n",
    "            grad = estimate_gradient(z, q, beta, loss)  # 使用QMO计算离散梯度\n",
    "            if use_adam:\n",
    "                z.grad = grad\n",
    "            else:\n",
    "                lr = ((1 - i/max_iter)**0.5) * base_lr\n",
    "                z -= grad * lr\n",
    "            \n",
    "            mol = model_decode(z)   # 将优化后的embedding还原为序列\n",
    "            print('After optim ', mol)\n",
    "            mol_score = score and -score(mol, seq)\n",
    "            print('score is %f'%mol_score)\n",
    "            print('AMP : %d, Toxic: %d'%(constraints[0](mol), constraints[1](mol)))\n",
    "            if (score is None or mol_score > best['score']) and all(c(mol) == 0 for c in constraints):\n",
    "                # best.update(desc)\n",
    "                print('Bingo!')\n",
    "                best.update(dict(step=i, z=z, z_0=z_0, seq=mol,\n",
    "                                 score=mol_score, found=True, run=k,\n",
    "                                  early_stop=early_stop))\n",
    "\n",
    "                print(f'PASSED!')\n",
    "\n",
    "                if early_stop:\n",
    "                    break\n",
    "            print()\n",
    "            \n",
    "    if not best['found']:\n",
    "        print('Search failed!')\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 'WFHHIFRGIVHVGKTIHRLVTG'\n",
    "optimize(model,seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 'AKKVFKRLGIGAVLWVLTTG'\n",
    "optimize(model,seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maeseq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
